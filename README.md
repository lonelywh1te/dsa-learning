# Оглавление
- [Оглавление](#оглавление)
- [Асимптотическая сложность. О-нотация](#асимптотическая-сложность-о-нотация)
  - [Понятие асимптотической сложности](#понятие-асимптотической-сложности)
  - [Big-O нотация](#big-o-нотация)
# Асимптотическая сложность. О-нотация
## Понятие асимптотической сложности

> *Асимптотическая сложность - это концепция в теории вычислительной сложности, которая описывает поведение алгоритма при увеличении размера входных данных. Она позволяет нам сравнивать эффективность различных алгоритмов независимо от конкретных значений входных данных.*

В общем виде, асимптотическая сложность алгоритма определяется как функция, которая описывает количество операций, которые должен выполнить алгоритм, в зависимости от размера входных данных. Эта функция обычно обозначается как O(n), где n - это размер входных данных.  

Асимптотическая сложность может быть выражена в терминах больших O, Ω (Омега) и Θ (Тета). Большие O используются для верхней границы сложности, Ω - для нижней границы, а Θ - когда верхняя и нижняя границы совпадают.

Например, если мы говорим, что алгоритм имеет асимптотическую сложность O(n^2), это означает, что время выполнения алгоритма будет расти **квадратично** с увеличением размера входных данных. Если же мы говорим, что алгоритм имеет асимптотическую сложность O(log n), это означает, что время выполнения алгоритма будет расти **логарифмически** с увеличением размера входных данных.

[`Изучить подробнее`](https://www.geeksforgeeks.org/types-of-asymptotic-notations-in-complexity-analysis-of-algorithms/)

## Big-O нотация
![Big-O Complexity](images/big-o-complexity.png)
> *Big-O нотация представляет собой математическое выражение, описывающее ограничение сверху скорости роста функции, которая определяет количество операций, выполняемых алгоритмом*

Основная цель Big-O нотации - предоставить инструмент для сравнения эффективности различных алгоритмов. Это позволяет программистам выбирать наиболее эффективный алгоритм для конкретной задачи, учитывая объем данных, с которыми он будет работать.

Вот некоторые общие типы временной сложности и соответствующие им Big O нотации:

- **O(1)**: Константная временная сложность. Это наилучший случай, когда время выполнения алгоритма не зависит от размера входных данных. Примером может служить доступ к элементу массива по индексу.

- **O(log n)**: Логарифмическая временная сложность. Это хорошо, когда размер входных данных уменьшается вдвое с каждым шагом, например, при бинарном поиске.

- **O(n)**: Линейная временная сложность. Это происходит, когда вы имеете один цикл в вашем алгоритме. Примером может служить простой перебор всех элементов массива.

- **O(n log n)**: Временная сложность, которую можно найти в алгоритмах сортировки, таких как сортировка слиянием и быстрая сортировка.

- **O(n^2)**: Квадратичная временная сложность. Это происходит, когда у вас есть вложенные циклы в вашем алгоритме. Примером может служить алгоритм пузырьковой сортировки.

- **O(2^n)**: Экспоненциальная временная сложность. Это происходит, когда время выполнения алгоритма удваивается с каждым новым элементом входных данных. Примером может служить алгоритм перебора подмножеств.
  
Важно помнить, что эти нотации описывают только верхнюю границу времени выполнения алгоритма, то есть максимальное возможное время выполнения.

[`Изучить подробнее`](https://www.geeksforgeeks.org/analysis-algorithms-big-o-analysis/)
